{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"Copy of FixImageSet.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1zbw9lBJ02Bj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618957605040,"user_tz":-60,"elapsed":437,"user":{"displayName":"edward ward","photoUrl":"","userId":"13037739191521860750"}},"outputId":"1aaeacae-f2f7-45e5-a5b4-1d74f56fafda"},"source":["import numpy as np\n","from tqdm.notebook import tqdm\n","import glob\n","import sys\n","import os\n","from PIL import Image\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"aAtS78kN02Bn"},"source":["import argparse\n","def GetParams():\n","  opt = argparse.Namespace()\n","\n","  opt.model='rcan'#'model to use'\n","  opt.lr = 0.0001 # learning rate\n","  opt.norm = '' # if normalization should not be used\n","  opt.nepoch =100 # number of epochs to train for\n","  opt.saveinterval =1 # number of epochs between saves\n","  opt.modifyPretrainedModel = False\n","  opt.multigpu = False\n","  opt.undomulti = False\n","  opt.ntrain = 5000 # number of samples to train on\n","  opt.scheduler = '' # options for a scheduler, format: stepsize,gamma\n","  opt.log = False\n","  opt.noise ='' # options for noise added, format: poisson,gaussVar\n","\n","  # data\n","  opt.dataset = 'fouriersim' # dataset to train\n","  opt.imageSize = 512 # the low resolution image size\n","  opt.weights = 'D:/User/Edward/Downloads/HPC-download/prelim32.pth' # model to retrain from\n","  opt.basedir = '' # path to prepend to all others paths: root, output, weights\n","  opt.root ='D:/Work/Test datasets/OS-SIM' # dataset to train\n","  opt.server = '' # whether to use server root preset\n","  opt.local = '' # whether to use local root preset: C:/phd-data/datasets/\n","  opt.out = 'D:/Work/Test datasets/OS-SIM/ML-SIM reconstructions/HPC 01-05-2021' # folder to output model training results\n","\n","  # computation \n","  opt.workers  = 1 # number of data loading workers\n","  opt.batchSize = 10 # input batch size\n","\n","  # restoration options\n","  opt.task ='sr' # restoration task \n","  opt.scale = 1 # low to high resolution scaling factor\n","  opt.nch_in = 3 # channels in input \n","  opt.nch_out = 1 # channels in output \n","\n","  # architecture options \n","  opt.narch = 0 # architecture-dependent parameter\n","  opt.n_resblocks  = 2 # number of residual blocks \n","  opt.n_resgroups  = 3 # number of residual groups \n","  opt.reduction  = 2 # number of 36eature maps\n","  opt.n_feats = 54 \n","\n","  # test options\n","  opt.ntest  = 10 # number of images to test per epoch or test run \n","  opt.testinterval  = 1 # number of epochs between tests during training \n","  opt.test = False\n","  opt.cpu = False # not supported for training\n","  opt.batchSize_test  = 1 # input batch size for test loader \n","  opt.plotinterval  = 1 # number of test samples between plotting \n","    \n","  return opt"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b08oUqD0qYPP","executionInfo":{"status":"ok","timestamp":1618957608191,"user_tz":-60,"elapsed":3573,"user":{"displayName":"edward ward","photoUrl":"","userId":"13037739191521860750"}},"outputId":"549bc593-c0df-446b-8650-ad0ac29ca1fe"},"source":["\n","import math\n","import os\n","\n","import torch\n","import time \n","\n","import torch.optim as optim\n","import torchvision\n","from torch.autograd import Variable\n","\n","from skimage import io\n","from models import *\n","from datahandler import *\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import glob\n","\n","def remove_dataparallel_wrapper(state_dict):\n","\tr\"\"\"Converts a DataParallel model to a normal one by removing the \"module.\"\n","\twrapper in the module dictionary\n","\n","\tArgs:\n","\t\tstate_dict: a torch.nn.DataParallel state dictionary\n","\t\"\"\"\n","\tfrom collections import OrderedDict\n","\n","\tnew_state_dict = OrderedDict()\n","\tfor k, vl in state_dict.items():\n","\t\tname = k[7:] # remove 'module.' of DataParallel\n","\t\tnew_state_dict[name] = vl\n","\n","\treturn new_state_dict\n","\n","\n","def changeColour(I): # change colours (used to match WEKA output)\n","    Inew = np.zeros(I.shape + (3,)).astype('uint8')\n","    for rowidx in range(I.shape[0]):\n","        for colidx in range(I.shape[1]):\n","            if I[rowidx][colidx] == 0:\n","                Inew[rowidx][colidx] = [198,118,255]\n","            elif I[rowidx][colidx] == 127:\n","                Inew[rowidx][colidx] = [79,255,130]\n","            elif I[rowidx][colidx] == 255:\n","                Inew[rowidx][colidx] = [255,0,0]\n","    return Inew\n","\n","\n","def loadimg(imgfile):\n","    stack = io.imread(imgfile)\n","    inputimgs,wfimgs = [],[]\n","\n","    for i in range(int(len(stack)/9)):\n","        inputimg = stack[i*9:(i+1)*9]\n","\n","        if inputimg.shape[1] != 512 or inputimg.shape[2] != 512:\n","            print(imgfile,'not 512x512! Cropping')\n","            inputimg = inputimg[:,:512,:512]\n","                 \n","        widefield = np.mean(inputimg,0)\n","        widefield = (widefield - np.min(widefield)) / (np.max(widefield) - np.min(widefield))    \n","\n","\n","        if opt.norm == 'convert': # raw img from microscope, needs normalisation and correct frame ordering\n","            print('Raw input assumed - converting')\n","\n","\n","            inputimg = np.rot90(inputimg,axes=(1,2))\n","            inputimg = inputimg[[6,7,8,3,4,5,0,1,2]] # could also do [8,7,6,5,4,3,2,1,0]\n","            for i in range(len(inputimg)):\n","                inputimg[i] = 100 / np.max(inputimg[i]) * inputimg[i]\n","            inputimg = torch.tensor(inputimg.astype('float') / 255).float()\n","        elif 'convert' in opt.norm:\n","            fac = float(opt.norm[7:])\n","            inputimg = np.rot90(inputimg,axes=(1,2))\n","            inputimg = inputimg[[6,7,8,3,4,5,0,1,2]] # could also do [8,7,6,5,4,3,2,1,0]\n","            for i in range(len(inputimg)):\n","                inputimg[i] = fac * 255 / np.max(inputimg[i]) * inputimg[i]\n","            inputimg = torch.tensor(inputimg.astype('float') / 255).float()\n","        elif opt.norm == 'minmax':\n","            inputimg = torch.tensor(inputimg.astype('float') / 255).float()\n","            for i in range(len(inputimg)):\n","                inputimg[i] = (inputimg[i] - torch.min(inputimg[i])) / (torch.max(inputimg[i]) - torch.min(inputimg[i]))\n","\n","        else:\n","            inputimg = torch.tensor(inputimg.astype('float') / 255).float()\n","\n","\n","        widefield = torch.tensor(widefield).float()\n","        \n","        inputimgs.append(inputimg)\n","        wfimgs.append(widefield)\n","\n","    return inputimgs,wfimgs\n","\n","\n","def EvaluateModel(opt):\n","\n","    try:\n","        os.makedirs(opt.out)\n","    except IOError:\n","        pass\n","\n","    opt.fid = open(opt.out + '/log.txt','w')\n","    print(opt)\n","    print(opt,'\\n',file=opt.fid)\n","    \n","    net = GetModel(opt)\n","\n","    checkpoint = torch.load(opt.weights)\n","    if opt.cpu:\n","        net.cpu()\n","    \n","    print('loading checkpoint',opt.weights)\n","    if opt.undomulti:\n","        checkpoint['state_dict'] = remove_dataparallel_wrapper(checkpoint['state_dict'])\n","    net.load_state_dict(checkpoint['state_dict'])\n","\n","    if opt.root.split('.')[-1] == 'png' or opt.root.split('.')[-1] == 'jpg':\n","        imgs = [opt.root]\n","    else:\n","        imgs = []\n","        imgs.extend(glob.glob(opt.root + '/*.jpg'))\n","        imgs.extend(glob.glob(opt.root + '/*.png'))\n","        imgs.extend(glob.glob(opt.root + '/*.tif'))\n","        if len(imgs) == 0: # scan everything\n","            imgs.extend(glob.glob(opt.root + '/**/*.jpg',recursive=True))\n","            imgs.extend(glob.glob(opt.root + '/**/*.png',recursive=True))\n","            imgs.extend(glob.glob(opt.root + '/**/*.tif',recursive=True))\n","\n","    imageSize = opt.imageSize\n","\n","    for i, imgfile in enumerate(imgs):\n","        print('\\rProcessing image [%d/%d]' % (i+1,len(imgs)),end='')\n","        img = io.imread(imgfile)\n","        img = np.array(img)\n","        img = img/np.amax(img)\n","\n","        nImgs = img.shape[0] // opt.nch_in\n","        srs = np.zeros([512,512,nImgs]) \n","        wfs = np.zeros([512,512,nImgs])\n","\n","        if img.shape[1] != 512:\n","            print('\\rimage', imgfile,' is not 512x512! Cropping')\n","            img = img[:,:512,:512]\n","\n","        frames = np.zeros([512,512,nImgs])\n","        for stack_idx in tqdm(range(nImgs // opt.nch_in)):\n","            stackSubset = img[stack_idx*opt.nch_in:(stack_idx+1)*opt.nch_in] \n","            wfs[:,:,stack_idx] = np.mean(stackSubset,0)\n","\n","            sub_tensor = toTensor(np.moveaxis(stackSubset,0,2))\n","            sub_tensor = sub_tensor.unsqueeze(0)\n","            sub_tensor = sub_tensor.type(torch.FloatTensor)\n","            \n","            \n","            with torch.no_grad():\n","                if opt.cpu:\n","                    sr = net(sub_tensor)\n","                else:\n","                    sr = net(sub_tensor.cuda())\n","                sr = sr.cpu()\n","\n","                sr = torch.clamp(sr[0],0,1)\n","                sr_frame = sr.numpy()\n","                sr_frame = np.squeeze(sr_frame)\n","                srs[:,:,stack_idx] = sr_frame\n","                               \n","\n","\n","\n","        frames = (frames * 32000).astype('uint16')\n","        if nImgs > 1:\n","            frames = np.moveaxis(frames,2,0)\n","        \n","        filename = os.path.basename(imgfile)[:-4]\n","        svPath = opt.out + '/' + filename +'_sr.tif'\n","        io.imsave(svPath,frames)\n","\n","\n","\n","if __name__ == '__main__':\n","    opt = GetParams()\n","\n","    EvaluateModel(opt)\n"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(basedir='', batchSize=10, batchSize_test=1, cpu=False, dataset='fouriersim', fid=<_io.TextIOWrapper name='D:/Work/Test datasets/OS-SIM/ML-SIM reconstructions/HPC 01-05-2021/log.txt' mode='w' encoding='cp1252'>, imageSize=512, local='', log=False, lr=0.0001, model='rcan', modifyPretrainedModel=False, multigpu=False, n_feats=54, n_resblocks=2, n_resgroups=3, narch=0, nch_in=3, nch_out=1, nepoch=100, noise='', norm='', ntest=10, ntrain=5000, out='D:/Work/Test datasets/OS-SIM/ML-SIM reconstructions/HPC 01-05-2021', plotinterval=1, reduction=2, root='D:/Work/Test datasets/OS-SIM', saveinterval=1, scale=1, scheduler='', server='', task='sr', test=False, testinterval=1, undomulti=False, weights='D:/User/Edward/Downloads/HPC-download/prelim32.pth', workers=1)\n","not using normalization\n","  0%|          | 0/3 [00:00<?, ?it/s]loading checkpoint D:/User/Edward/Downloads/HPC-download/prelim32.pth\n","100%|██████████| 3/3 [00:00<00:00,  5.93it/s]\n","100%|██████████| 20/20 [00:03<00:00,  6.08it/s]\n","100%|██████████| 30/30 [00:05<00:00,  5.93it/s]\n","100%|██████████| 30/30 [00:05<00:00,  5.92it/s]\n","100%|██████████| 8/8 [00:01<00:00,  5.80it/s]\n","100%|██████████| 40/40 [00:06<00:00,  6.05it/s]\n","100%|██████████| 40/40 [00:06<00:00,  5.89it/s]\n","100%|██████████| 40/40 [00:06<00:00,  5.88it/s]\n","100%|██████████| 40/40 [00:06<00:00,  5.76it/s]\n","100%|██████████| 40/40 [00:06<00:00,  5.87it/s]\n","100%|██████████| 6/6 [00:01<00:00,  5.65it/s]\n","100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n","100%|██████████| 1/1 [00:00<00:00,  6.11it/s]\n","100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\n","100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n","100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n","100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n","100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n","100%|██████████| 10/10 [00:01<00:00,  6.10it/s]\n","100%|██████████| 33/33 [00:05<00:00,  5.95it/s]\n","100%|██████████| 16/16 [00:02<00:00,  5.93it/s]\n","100%|██████████| 1/1 [00:00<00:00,  5.29it/s]\n","100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n","100%|██████████| 6/6 [00:00<00:00,  6.03it/s]\n","100%|██████████| 8/8 [00:01<00:00,  6.07it/s]\n","100%|██████████| 8/8 [00:01<00:00,  6.02it/s]\n","100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n","100%|██████████| 30/30 [00:04<00:00,  6.06it/s]\n","100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n","100%|██████████| 20/20 [00:03<00:00,  5.99it/s]\n","100%|██████████| 25/25 [00:04<00:00,  5.98it/s]\n","100%|██████████| 25/25 [00:04<00:00,  5.95it/s]\n","100%|██████████| 10/10 [00:01<00:00,  5.72it/s]\n"]}]},{"source":[" opt.out"],"cell_type":"code","metadata":{"id":"AJV3IDmZ1DE-"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'D:/Work/Test datasets/OS-SIM/ML-SIM reconstructions/HPC 01-05-2021'"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}