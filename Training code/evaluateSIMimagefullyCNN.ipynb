{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"Copy of FixImageSet.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1zbw9lBJ02Bj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618957605040,"user_tz":-60,"elapsed":437,"user":{"displayName":"edward ward","photoUrl":"","userId":"13037739191521860750"}},"outputId":"1aaeacae-f2f7-45e5-a5b4-1d74f56fafda"},"source":["import numpy as np\n","from tqdm.notebook import tqdm\n","import glob\n","import sys\n","import os\n","from PIL import Image\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"aAtS78kN02Bn"},"source":["import argparse\n","def GetParams():\n","  opt = argparse.Namespace()\n","\n","  opt.model='rcan'#'model to use'\n","  opt.lr = 0.0001 # learning rate\n","  opt.norm = 'minmax' # if normalization should not be used\n","  opt.nepoch =100 # number of epochs to train for\n","  opt.saveinterval =1 # number of epochs between saves\n","  opt.modifyPretrainedModel = False\n","  opt.multigpu = False\n","  opt.undomulti = False\n","  opt.ntrain = 5000 # number of samples to train on\n","  opt.scheduler = '' # options for a scheduler, format: stepsize,gamma\n","  opt.log = False\n","  opt.noise ='' # options for noise added, format: poisson,gaussVar\n","\n","  # data\n","  opt.dataset = 'fouriersim' # dataset to train\n","  opt.imageSize = 255 # the low resolution image size\n","  opt.weights = 'D:/ML-SIM/OS-SIM/255 models/generated 27-05-2021/results/prelim92.pth' # model to retrain from\n","  opt.basedir = '' # path to prepend to all others paths: root, output, weights\n","  opt.root ='D:/User/Edward/Downloads/forHPC/test data/' # dataset to train\n","  opt.server = '' # whether to use server root preset\n","  opt.local = '' # whether to use local root preset: C:/phd-data/datasets/\n","  opt.out = 'D:/ML-SIM/OS-SIM/ML-SIM reconstructions/generated 27-05-2021/' # folder to output model training results\n","\n","  # computation \n","  opt.workers  = 1 # number of data loading workers\n","  opt.batchSize = 10 # input batch size\n","\n","  # restoration options\n","  opt.task ='sr' # restoration task \n","  opt.scale = 1 # low to high resolution scaling factor\n","  opt.nch_in = 3 # channels in input \n","  opt.nch_out = 1 # channels in output \n","\n","  # architecture options \n","  opt.narch = 0 # architecture-dependent parameter\n","  opt.n_resblocks  = 3 # number of residual blocks \n","  opt.n_resgroups  = 5 # number of residual groups \n","  opt.reduction  = 16 # number of 36eature maps\n","  opt.n_feats = 96 \n","\n","  # test options\n","  opt.ntest  = 10 # number of images to test per epoch or test run \n","  opt.testinterval  = 1 # number of epochs between tests during training \n","  opt.test = False\n","  opt.cpu = False # not supported for training\n","  opt.batchSize_test  = 1 # input batch size for test loader \n","  opt.plotinterval  = 1 # number of test samples between plotting \n","    \n","  return opt"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b08oUqD0qYPP","executionInfo":{"status":"ok","timestamp":1618957608191,"user_tz":-60,"elapsed":3573,"user":{"displayName":"edward ward","photoUrl":"","userId":"13037739191521860750"}},"outputId":"549bc593-c0df-446b-8650-ad0ac29ca1fe"},"source":["\n","import math\n","import os\n","\n","import torch\n","import time \n","\n","import torch.optim as optim\n","import torchvision\n","from torch.autograd import Variable\n","\n","from skimage import io\n","from models import *\n","from datahandler import *\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import glob\n","\n","def remove_dataparallel_wrapper(state_dict):\n","\tr\"\"\"Converts a DataParallel model to a normal one by removing the \"module.\"\n","\twrapper in the module dictionary\n","\n","\tArgs:\n","\t\tstate_dict: a torch.nn.DataParallel state dictionary\n","\t\"\"\"\n","\tfrom collections import OrderedDict\n","\n","\tnew_state_dict = OrderedDict()\n","\tfor k, vl in state_dict.items():\n","\t\tname = k[7:] # remove 'module.' of DataParallel\n","\t\tnew_state_dict[name] = vl\n","\n","\treturn new_state_dict\n","\n","\n","def changeColour(I): # change colours (used to match WEKA output)\n","    Inew = np.zeros(I.shape + (3,)).astype('uint8')\n","    for rowidx in range(I.shape[0]):\n","        for colidx in range(I.shape[1]):\n","            if I[rowidx][colidx] == 0:\n","                Inew[rowidx][colidx] = [198,118,255]\n","            elif I[rowidx][colidx] == 127:\n","                Inew[rowidx][colidx] = [79,255,130]\n","            elif I[rowidx][colidx] == 255:\n","                Inew[rowidx][colidx] = [255,0,0]\n","    return Inew\n","\n","\n","def loadimg(imgfile):\n","    stack = io.imread(imgfile)\n","    inputimgs,wfimgs = [],[]\n","\n","    for i in range(int(len(stack)/9)):\n","        inputimg = stack[i*9:(i+1)*9]\n","\n","        if inputimg.shape[1] != 512 or inputimg.shape[2] != 512:\n","            print(imgfile,'not 512x512! Cropping')\n","            inputimg = inputimg[:,:512,:512]\n","                 \n","        widefield = np.mean(inputimg,0)\n","        widefield = (widefield - np.min(widefield)) / (np.max(widefield) - np.min(widefield))    \n","\n","\n","        if opt.norm == 'convert': # raw img from microscope, needs normalisation and correct frame ordering\n","            print('Raw input assumed - converting')\n","\n","\n","            inputimg = np.rot90(inputimg,axes=(1,2))\n","            inputimg = inputimg[[6,7,8,3,4,5,0,1,2]] # could also do [8,7,6,5,4,3,2,1,0]\n","            for i in range(len(inputimg)):\n","                inputimg[i] = 100 / np.max(inputimg[i]) * inputimg[i]\n","            inputimg = torch.tensor(inputimg.astype('float') / 255).float()\n","        elif 'convert' in opt.norm:\n","            fac = float(opt.norm[7:])\n","            inputimg = np.rot90(inputimg,axes=(1,2))\n","            inputimg = inputimg[[6,7,8,3,4,5,0,1,2]] # could also do [8,7,6,5,4,3,2,1,0]\n","            for i in range(len(inputimg)):\n","                inputimg[i] = fac * 255 / np.max(inputimg[i]) * inputimg[i]\n","            inputimg = torch.tensor(inputimg.astype('float') / 255).float()\n","        elif opt.norm == 'minmax':\n","            inputimg = torch.tensor(inputimg.astype('float') / 255).float()\n","            for i in range(len(inputimg)):\n","                inputimg[i] = (inputimg[i] - torch.min(inputimg[i])) / (torch.max(inputimg[i]) - torch.min(inputimg[i]))\n","\n","        else:\n","            inputimg = torch.tensor(inputimg.astype('float') / 255).float()\n","\n","\n","        widefield = torch.tensor(widefield).float()\n","        \n","        inputimgs.append(inputimg)\n","        wfimgs.append(widefield)\n","\n","    return inputimgs,wfimgs\n","\n","\n","def EvaluateModel(opt):\n","\n","    try:\n","        os.makedirs(opt.out)\n","    except IOError:\n","        pass\n","\n","    opt.fid = open(opt.out + '/log.txt','w')\n","    print(opt)\n","    print(opt,'\\n',file=opt.fid)\n","    \n","    net = GetModel(opt)\n","\n","    checkpoint = torch.load(opt.weights)\n","    if opt.cpu:\n","        net.cpu()\n","    \n","    print('loading checkpoint',opt.weights)\n","    if opt.undomulti:\n","        checkpoint['state_dict'] = remove_dataparallel_wrapper(checkpoint['state_dict'])\n","    net.load_state_dict(checkpoint['state_dict'])\n","\n","    if opt.root.split('.')[-1] == 'png' or opt.root.split('.')[-1] == 'jpg':\n","        imgs = [opt.root]\n","    else:\n","        imgs = []\n","        imgs.extend(glob.glob(opt.root + '/*.jpg'))\n","        imgs.extend(glob.glob(opt.root + '/*.png'))\n","        imgs.extend(glob.glob(opt.root + '/*.tif'))\n","        if len(imgs) == 0: # scan everything\n","            imgs.extend(glob.glob(opt.root + '/**/*.jpg',recursive=True))\n","            imgs.extend(glob.glob(opt.root + '/**/*.png',recursive=True))\n","            imgs.extend(glob.glob(opt.root + '/**/*.tif',recursive=True))\n","\n","    imageSize = opt.imageSize\n","\n","    for i, imgfile in enumerate(imgs):\n","        description = 'Processing image [%d/%d]' % (i+1,len(imgs))\n","        img = io.imread(imgfile)\n","        img = np.array(img)\n","        img = img/np.amax(img)\n","\n","        nImgs = img.shape[0] // opt.nch_in\n","\n","        X = img.shape[1]\n","        Y = img.shape[2]\n","\n","#        if img.shape[1] != 512:\n","#            print('\\rimage', imgfile,' is not 512x512! Cropping')\n","#            img = img[:,:512,:512]\n","\n","        frames = np.zeros([X,Y,nImgs])\n","        srs = np.zeros([X,Y,nImgs]) \n","        wfs = np.zeros([X,Y,nImgs])\n","\n","        for stack_idx in tqdm(range(nImgs),desc=description):\n","            stackSubset = img[stack_idx*opt.nch_in:(stack_idx+1)*opt.nch_in] \n","            wfs[:,:,stack_idx] = np.mean(stackSubset,0)\n","\n","            sub_tensor = toTensor(np.moveaxis(stackSubset,0,2))\n","            sub_tensor = sub_tensor.unsqueeze(0)\n","            sub_tensor = sub_tensor.type(torch.FloatTensor)\n","            \n","            \n","            with torch.no_grad():\n","                if opt.cpu:\n","                    sr = net(sub_tensor)\n","                else:\n","                    sr = net(sub_tensor.cuda())\n","                sr = sr.cpu()\n","\n","                sr = torch.clamp(sr[0],0,1)\n","                sr_frame = sr.numpy()\n","                sr_frame = np.squeeze(sr_frame)\n","                frames[:,:,stack_idx] = sr_frame\n","                               \n","\n","\n","        wfs = (wfs * 32000).astype('uint16')\n","        if nImgs > 1:\n","            wfs = np.moveaxis(wfs,2,0)\n","        \n","        frames = (frames * 32000).astype('uint16')\n","        if nImgs > 1:\n","            frames = np.moveaxis(frames,2,0)\n","        \n","        filename = os.path.basename(imgfile)[:-4]\n","        svPath = opt.out + '/' + filename +'_sr.tif'\n","        io.imsave(svPath,frames)\n","        svPath = opt.out + '/' + filename +'_wf.tif'\n","        io.imsave(svPath,wfs)\n","\n","\n","if __name__ == '__main__':\n","    opt = GetParams()\n","\n","    EvaluateModel(opt)\n"],"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'noise'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m<ipython-input-3-59012423710b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatahandler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\User\\Edward\\Documents\\GitHub\\ML OS-SIM\\Training code\\datahandler.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mHDF5Dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mnoise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\User\\Edward\\Documents\\GitHub\\ML OS-SIM\\Training code\\datahandler.py\u001b[0m in \u001b[0;36mHDF5Dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHDF5Dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mnoise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# highres images not currently scaled, optdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'noise'"]}]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}